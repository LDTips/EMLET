{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb6a6862-9ab9-47c7-b5da-0bc772897129",
   "metadata": {},
   "source": [
    "# Training a ML model using CICIoT2023\n",
    "\n",
    "This notebook shows how a LogisticRegression model can be trained using the CICIoT2023 csv files."
   ]
  },
  {
   "cell_type": "code",
   "id": "40f7c50d-b0ae-4f19-9398-1435ba7a851d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T23:16:31.132834Z",
     "start_time": "2024-06-02T23:16:31.114411Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import random\n",
    "SEED = 97  # Set to None for randomness\n",
    "if SEED:\n",
    "    random.seed(SEED)\n",
    "    print(f\"INFO: Using seed {SEED}\")\n",
    "else:\n",
    "    print(f\"Using random seed\")\n",
    "\n",
    "# Manual train/test splitting\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using seed 97\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "5c40b5d2-727b-4f37-a480-9d46304eb541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T23:16:31.144319Z",
     "start_time": "2024-06-02T23:16:31.135872Z"
    }
   },
   "source": [
    "DATASET_DIRECTORY = '../CICIoT2023/'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "3ec1f2b2-92b3-4622-895b-6ac5126f30b4",
   "metadata": {},
   "source": [
    "### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "6854f877-5524-46ba-b7ca-5d6040015f44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T23:16:31.158067Z",
     "start_time": "2024-06-02T23:16:31.146368Z"
    }
   },
   "source": [
    "df_sets = [k for k in os.listdir(DATASET_DIRECTORY) if k.endswith('.csv')]\n",
    "df_sets.sort()\n",
    "test_indexes_count = int(len(df_sets)*0.2)\n",
    "train_indexes_count = int(len(df_sets)*0.8)\n",
    "index_range = range(len(df_sets))\n",
    "test_indexes = random.sample(index_range, test_indexes_count)\n",
    "train_indexes = [i for i in index_range if i not in test_indexes]\n",
    "training_sets, test_sets = [], []\n",
    "for i in train_indexes:\n",
    "    training_sets.append(df_sets[i])\n",
    "for i in test_indexes:\n",
    "    test_sets.append(df_sets[i])\n",
    "# training_sets = df_sets[:int(len(df_sets)*.8)]\n",
    "# test_sets = df_sets[int(len(df_sets)*.8):]"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "0433838d-ca57-4dd8-b41c-ad2ee3df61c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T23:16:31.167491Z",
     "start_time": "2024-06-02T23:16:31.159932Z"
    }
   },
   "source": [
    "X_columns = [\n",
    "    'flow_duration', 'Header_Length', 'Protocol Type', 'Duration',\n",
    "       'Rate', 'Srate', 'Drate', 'fin_flag_number', 'syn_flag_number',\n",
    "       'rst_flag_number', 'psh_flag_number', 'ack_flag_number',\n",
    "       'ece_flag_number', 'cwr_flag_number', 'ack_count',\n",
    "       'syn_count', 'fin_count', 'urg_count', 'rst_count', \n",
    "    'HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP',\n",
    "       'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC', 'Tot sum', 'Min',\n",
    "       'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue',\n",
    "       'Radius', 'Covariance', 'Variance', 'Weight', \n",
    "]\n",
    "y_column = 'label'"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "249673a6-4826-4b80-b9aa-dfa4c3d549c4",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "id": "cba40f31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T23:16:31.423229Z",
     "start_time": "2024-06-02T23:16:31.169513Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "scaler = StandardScaler()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "3682559f-9eb3-4d35-b1b2-d7d501ab85bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T23:19:35.399332Z",
     "start_time": "2024-06-02T23:16:31.424259Z"
    }
   },
   "source": [
    "scaler_filename = f\"precomputed/scaler-{SEED}.save\"\n",
    "\n",
    "if os.path.exists(scaler_filename) and SEED is not None:\n",
    "    scaler = joblib.load(scaler_filename) \n",
    "else:\n",
    "    scaler = StandardScaler()\n",
    "    for train_set in tqdm(train_indexes):\n",
    "        scaler.fit(pd.read_csv(DATASET_DIRECTORY + '/' + df_sets[train_set])[X_columns])\n",
    "    if SEED is not None:\n",
    "        joblib.dump(scaler, scaler_filename)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1adc23828014a55a1917b7f66698996"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "60abc3f0-e32d-40be-abc5-fd5972cf9856",
   "metadata": {},
   "source": [
    "### Classification: 34 (33+1) classes"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "ML_models = [ # or 'rbf', 'poly' for different kernels\n",
    "        LogisticRegression(),\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        xgb.XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            learning_rate=0.1,\n",
    "            random_state=SEED\n",
    "        ),\n",
    "        \n",
    "]\n",
    "\n",
    "ML_neams = [\n",
    "        'LogisticRegresion',\n",
    "        'Decision Tree',\n",
    "        'Random Forest',\n",
    "        'Xtra Gradient Boost'\n",
    "]\n",
    "label_encoder = LabelEncoder()\n",
    "for train_set in tqdm(training_sets):\n",
    "    d = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "    d[X_columns] = scaler.transform(d[X_columns])\n",
    "    for i, model in enumerate(ML_models):\n",
    "        if i == len(ML_models)-1:\n",
    "            d[y_column] = label_encoder.fit_transform(d[y_column])\n",
    "        print(f\"Currently training {ML_neams[i]}\")\n",
    "        model.fit(d[X_columns], d[y_column])\n",
    "    del d"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-02T23:19:35.402106Z"
    }
   },
   "id": "d208cf46-8ba9-480f-ab99-d4ee81c083b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/136 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab0162927b9e427fa9f18445129fd1c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently training LogisticRegresion\n",
      "Currently training Decision Tree\n",
      "Currently training Random Forest\n",
      "Currently training Xtra Gradient Boost\n",
      "Currently training LogisticRegresion\n",
      "Currently training Decision Tree\n",
      "Currently training Random Forest\n",
      "Currently training Xtra Gradient Boost\n",
      "Currently training LogisticRegresion\n",
      "Currently training Decision Tree\n",
      "Currently training Random Forest\n",
      "Currently training Xtra Gradient Boost\n",
      "Currently training LogisticRegresion\n",
      "Currently training Decision Tree\n",
      "Currently training Random Forest\n",
      "Currently training Xtra Gradient Boost\n",
      "Currently training LogisticRegresion\n",
      "Currently training Decision Tree\n",
      "Currently training Random Forest\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6116132e-02f0-4bac-aefb-2ba0bee924ab",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "y_test = []\n",
    "preds = {i:[] for i in range(len(ML_models))}\n",
    "for test_set in tqdm(test_sets):\n",
    "    d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "    d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "    \n",
    "    y_test += list(d_test[y_column].values)\n",
    "    \n",
    "    for i in range(len(ML_models)):\n",
    "        model = ML_models[i]\n",
    "        y_pred = list(model.predict(d_test[X_columns]))\n",
    "        if i == len(ML_models)-1:\n",
    "            y_pred = label_encoder.inverse_transform(y_pred)\n",
    "        preds[i] = preds[i] + y_pred\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "375dcbfb-2b20-4b37-8fbb-c9d68a6ac541",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"### 34 CLASSES ###\")\n",
    "print(\"Model;accuracy;recall;precision;f1\")\n",
    "for k,v in preds.items():\n",
    "    y_pred = v\n",
    "    print(f\"{ML_neams[k]};{accuracy_score(y_pred, y_test)};{recall_score(y_pred, y_test, average='macro')};{precision_score(y_pred, y_test, average='macro')};{f1_score(y_pred, y_test, average='macro')}\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cn = ML_models[k].classes_\n",
    "    if ML_neams[k] == ML_neams[-1]:\n",
    "        cn = label_encoder.inverse_transform(ML_models[k].classes_)\n",
    "    \n",
    "    # plt.figure(figsize=(12, 9))\n",
    "    # sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=cn, yticklabels=cn)\n",
    "    # plt.xlabel('Predicted')\n",
    "    # plt.ylabel('Actual')\n",
    "    # plt.title('Confusion Matrix')\n",
    "    # plt.savefig('confusion_matrix_seaborn.png', dpi=500, bbox_inches='tight')\n",
    "    # plt.show()\n",
    "    \n",
    "    # Convert confusion matrix array to a DataFrame\n",
    "    cm_df = pd.DataFrame(cm, index=cn, columns=cn)\n",
    "    \n",
    "    # Export the DataFrame to a CSV file\n",
    "    cm_df.to_csv(f'cms/confusion_matrix-{ML_neams[k]}-34.csv')\n",
    "\n",
    "print('\\n\\n')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3958c6fa-6d05-48fb-a046-55e5843e4711",
   "metadata": {},
   "source": [
    "# Classification: 8 (7+1) classes"
   ]
  },
  {
   "cell_type": "code",
   "id": "9208c899-8b57-4a3a-a2e7-94b057123536",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "dict_7classes = {}\n",
    "dict_7classes['DDoS-RSTFINFlood'] = 'DDoS'\n",
    "dict_7classes['DDoS-PSHACK_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-SYN_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-UDP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-TCP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-ICMP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-SynonymousIP_Flood'] = 'DDoS'\n",
    "dict_7classes['DDoS-ACK_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-UDP_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-ICMP_Fragmentation'] = 'DDoS'\n",
    "dict_7classes['DDoS-SlowLoris'] = 'DDoS'\n",
    "dict_7classes['DDoS-HTTP_Flood'] = 'DDoS'\n",
    "\n",
    "dict_7classes['DoS-UDP_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-SYN_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-TCP_Flood'] = 'DoS'\n",
    "dict_7classes['DoS-HTTP_Flood'] = 'DoS'\n",
    "\n",
    "\n",
    "dict_7classes['Mirai-greeth_flood'] = 'Mirai'\n",
    "dict_7classes['Mirai-greip_flood'] = 'Mirai'\n",
    "dict_7classes['Mirai-udpplain'] = 'Mirai'\n",
    "\n",
    "dict_7classes['Recon-PingSweep'] = 'Recon'\n",
    "dict_7classes['Recon-OSScan'] = 'Recon'\n",
    "dict_7classes['Recon-PortScan'] = 'Recon'\n",
    "dict_7classes['VulnerabilityScan'] = 'Recon'\n",
    "dict_7classes['Recon-HostDiscovery'] = 'Recon'\n",
    "\n",
    "dict_7classes['DNS_Spoofing'] = 'Spoofing'\n",
    "dict_7classes['MITM-ArpSpoofing'] = 'Spoofing'\n",
    "\n",
    "dict_7classes['BenignTraffic'] = 'Benign'\n",
    "\n",
    "dict_7classes['BrowserHijacking'] = 'Web'\n",
    "dict_7classes['Backdoor_Malware'] = 'Web'\n",
    "dict_7classes['XSS'] = 'Web'\n",
    "dict_7classes['Uploading_Attack'] = 'Web'\n",
    "dict_7classes['SqlInjection'] = 'Web'\n",
    "dict_7classes['CommandInjection'] = 'Web'\n",
    "\n",
    "\n",
    "dict_7classes['DictionaryBruteForce'] = 'BruteForce'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4c1f697f-88d8-4ac4-8bc6-f1a8ac3794d5",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ML_models = [ # or 'rbf', 'poly' for different kernels\n",
    "        LogisticRegression(),\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        xgb.XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            learning_rate=0.1,\n",
    "            random_state=SEED\n",
    "        ),\n",
    "        \n",
    "]\n",
    "\n",
    "ML_neams = [\n",
    "        'LogisticRegresion',\n",
    "        'Decision Tree',\n",
    "        'Random Forest',\n",
    "        'Xtra Gradient Boost'\n",
    "]\n",
    "label_encoder = LabelEncoder()\n",
    "for train_set in tqdm(training_sets):\n",
    "    d = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "    d[X_columns] = scaler.transform(d[X_columns])\n",
    "    new_y = [dict_7classes[k] for k in d[y_column]]\n",
    "    d[y_column] = new_y\n",
    "    \n",
    "    for i, model in enumerate(ML_models):\n",
    "        if i == len(ML_models)-1:\n",
    "            d[y_column] = label_encoder.fit_transform(d[y_column])\n",
    "        model.fit(d[X_columns], d[y_column])\n",
    "    del d"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b69c509-7666-45bd-9e11-52ecec0df8a8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "y_test = []\n",
    "preds = {i:[] for i in range(len(ML_models))}\n",
    "for test_set in tqdm(test_sets):\n",
    "    d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "    d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "    new_y = [dict_7classes[k] for k in d_test[y_column]]\n",
    "    d_test[y_column] = new_y\n",
    "    \n",
    "    y_test += list(d_test[y_column].values)\n",
    "    \n",
    "    for i in range(len(ML_models)):\n",
    "        model = ML_models[i]\n",
    "        y_pred = list(model.predict(d_test[X_columns]))\n",
    "        if i == len(ML_models)-1:\n",
    "            y_pred = label_encoder.inverse_transform(y_pred)\n",
    "        preds[i] = preds[i] + y_pred\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3e0a9702-63f5-4898-a8b0-2bf950fe881d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "print(\"### 8 classes ###\")\n",
    "print(\"Model;accuracy;recall;precision;f1\")\n",
    "for k,v in preds.items():\n",
    "    y_pred = v\n",
    "    print(f\"{ML_neams[k]};{accuracy_score(y_pred, y_test)};{recall_score(y_pred, y_test, average='macro')};{precision_score(y_pred, y_test, average='macro')};{f1_score(y_pred, y_test, average='macro')}\")\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cn = ML_models[k].classes_\n",
    "    if ML_neams[k] == ML_neams[-1]:\n",
    "        cn = label_encoder.inverse_transform(ML_models[k].classes_)\n",
    "    \n",
    "    plt.figure(figsize=(12, 9))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=cn, yticklabels=cn)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix {ML_neams[k]} 7 classes')\n",
    "    plt.show()\n",
    "    \n",
    "    # Convert confusion matrix array to a DataFrame\n",
    "    cm_df = pd.DataFrame(cm, index=cn, columns=cn)\n",
    "    \n",
    "    # Export the DataFrame to a CSV file\n",
    "    cm_df.to_csv(f'cms/confusion_matrix-{ML_neams[k]}-7.csv')\n",
    "\n",
    "print('\\n\\n')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a6ecac59-fc02-4198-9910-daf890da7a0a",
   "metadata": {},
   "source": [
    "# Classification: 2 (1+1) Classes"
   ]
  },
  {
   "cell_type": "code",
   "id": "90ee4a99-d160-43bc-b2a0-06fa3f49e222",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "dict_2classes = {}\n",
    "dict_2classes['DDoS-RSTFINFlood'] = 'Attack'\n",
    "dict_2classes['DDoS-PSHACK_Flood'] = 'Attack'\n",
    "dict_2classes['DDoS-SYN_Flood'] = 'Attack'\n",
    "dict_2classes['DDoS-UDP_Flood'] = 'Attack'\n",
    "dict_2classes['DDoS-TCP_Flood'] = 'Attack'\n",
    "dict_2classes['DDoS-ICMP_Flood'] = 'Attack'\n",
    "dict_2classes['DDoS-SynonymousIP_Flood'] = 'Attack'\n",
    "dict_2classes['DDoS-ACK_Fragmentation'] = 'Attack'\n",
    "dict_2classes['DDoS-UDP_Fragmentation'] = 'Attack'\n",
    "dict_2classes['DDoS-ICMP_Fragmentation'] = 'Attack'\n",
    "dict_2classes['DDoS-SlowLoris'] = 'Attack'\n",
    "dict_2classes['DDoS-HTTP_Flood'] = 'Attack'\n",
    "\n",
    "dict_2classes['DoS-UDP_Flood'] = 'Attack'\n",
    "dict_2classes['DoS-SYN_Flood'] = 'Attack'\n",
    "dict_2classes['DoS-TCP_Flood'] = 'Attack'\n",
    "dict_2classes['DoS-HTTP_Flood'] = 'Attack'\n",
    "\n",
    "\n",
    "dict_2classes['Mirai-greeth_flood'] = 'Attack'\n",
    "dict_2classes['Mirai-greip_flood'] = 'Attack'\n",
    "dict_2classes['Mirai-udpplain'] = 'Attack'\n",
    "\n",
    "dict_2classes['Recon-PingSweep'] = 'Attack'\n",
    "dict_2classes['Recon-OSScan'] = 'Attack'\n",
    "dict_2classes['Recon-PortScan'] = 'Attack'\n",
    "dict_2classes['VulnerabilityScan'] = 'Attack'\n",
    "dict_2classes['Recon-HostDiscovery'] = 'Attack'\n",
    "\n",
    "dict_2classes['DNS_Spoofing'] = 'Attack'\n",
    "dict_2classes['MITM-ArpSpoofing'] = 'Attack'\n",
    "\n",
    "dict_2classes['BenignTraffic'] = 'Benign'\n",
    "\n",
    "dict_2classes['BrowserHijacking'] = 'Attack'\n",
    "dict_2classes['Backdoor_Malware'] = 'Attack'\n",
    "dict_2classes['XSS'] = 'Attack'\n",
    "dict_2classes['Uploading_Attack'] = 'Attack'\n",
    "dict_2classes['SqlInjection'] = 'Attack'\n",
    "dict_2classes['CommandInjection'] = 'Attack'\n",
    "\n",
    "dict_2classes['DictionaryBruteForce'] = 'Attack'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "506eae35-a310-4a34-8bcf-c99282ed3225",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "ML_models = [ # or 'rbf', 'poly' for different kernels\n",
    "        LogisticRegression(),\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier(),\n",
    "        xgb.XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            learning_rate=0.1,\n",
    "            random_state=SEED\n",
    "        ),\n",
    "        \n",
    "]\n",
    "\n",
    "ML_neams = [\n",
    "        'LogisticRegresion',\n",
    "        'Decision Tree',\n",
    "        'Random Forest',\n",
    "        'Xtra Gradient Boost'\n",
    "]\n",
    "label_encoder = LabelEncoder()\n",
    "for train_set in tqdm(training_sets):\n",
    "    d = pd.read_csv(DATASET_DIRECTORY + train_set)\n",
    "    d[X_columns] = scaler.transform(d[X_columns])\n",
    "    new_y = [dict_2classes[k] for k in d[y_column]]\n",
    "    d[y_column] = new_y\n",
    "    \n",
    "    for i, model in enumerate(ML_models):\n",
    "        if i == len(ML_models)-1:\n",
    "            d[y_column] = label_encoder.fit_transform(d[y_column])\n",
    "        model.fit(d[X_columns], d[y_column])\n",
    "    del d"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b07aa379-ec7e-4651-ab5a-6845ae249132",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "y_test = []\n",
    "preds = {i:[] for i in range(len(ML_models))}\n",
    "for test_set in tqdm(test_sets):\n",
    "    d_test = pd.read_csv(DATASET_DIRECTORY + test_set)\n",
    "    d_test[X_columns] = scaler.transform(d_test[X_columns])\n",
    "    new_y = [dict_2classes[k] for k in d_test[y_column]]\n",
    "    d_test[y_column] = new_y\n",
    "    \n",
    "    y_test += list(d_test[y_column].values)\n",
    "    \n",
    "    for i in range(len(ML_models)):\n",
    "        model = ML_models[i]\n",
    "        y_pred = list(model.predict(d_test[X_columns]))\n",
    "        if i == len(ML_models)-1:\n",
    "            y_pred = label_encoder.inverse_transform(y_pred)\n",
    "        preds[i] = preds[i] + y_pred\n",
    "        "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "caabf4fd-097d-4db2-847a-0dcd87144d6f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "print(\"### 2 classes ###\")\n",
    "print(\"Model;accuracy;recall;precision;f1\")\n",
    "for k,v in preds.items():\n",
    "    y_pred = v\n",
    "    print(f\"{ML_neams[k]};{accuracy_score(y_pred, y_test)};{recall_score(y_pred, y_test, average='macro')};{precision_score(y_pred, y_test, average='macro')};{f1_score(y_pred, y_test, average='macro')}\")\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cn = ML_models[k].classes_\n",
    "    if ML_neams[k] == ML_neams[-1]:\n",
    "        cn = label_encoder.inverse_transform(ML_models[k].classes_)\n",
    "    \n",
    "    plt.figure(figsize=(12, 9))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=cn, yticklabels=cn)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix {ML_neams[k]} 2 classes')\n",
    "    plt.show()\n",
    "    \n",
    "    # Convert confusion matrix array to a DataFrame\n",
    "    cm_df = pd.DataFrame(cm, index=cn, columns=cn)\n",
    "    \n",
    "    # Export the DataFrame to a CSV file\n",
    "    cm_df.to_csv(f'cms/confusion_matrix-{ML_neams[k]}-2.csv')\n",
    "\n",
    "print('\\n\\n')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b3919a1b582075e0",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
